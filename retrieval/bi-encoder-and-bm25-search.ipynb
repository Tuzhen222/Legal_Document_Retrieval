{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10259373,"sourceType":"datasetVersion","datasetId":6346501},{"sourceId":10459894,"sourceType":"datasetVersion","datasetId":6475501},{"sourceId":10459903,"sourceType":"datasetVersion","datasetId":6475507},{"sourceId":10459916,"sourceType":"datasetVersion","datasetId":6475518},{"sourceId":10515392,"sourceType":"datasetVersion","datasetId":6508786},{"sourceId":10515950,"sourceType":"datasetVersion","datasetId":6509133}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-gpu\n!pip install sentence_transformers\n!pip install einops\n!pip install --upgrade transformers sentence-transformers\n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:15:49.576360Z","iopub.execute_input":"2025-01-19T14:15:49.576603Z","iopub.status.idle":"2025-01-19T14:16:45.928076Z","shell.execute_reply.started":"2025-01-19T14:15:49.576571Z","shell.execute_reply":"2025-01-19T14:16:45.926799Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nCollecting sentence_transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.3.1\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nCollecting transformers\n  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.20.3\n    Uninstalling tokenizers-0.20.3:\n      Successfully uninstalled tokenizers-0.20.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.46.3\n    Uninstalling transformers-4.46.3:\n      Successfully uninstalled transformers-4.46.3\nSuccessfully installed tokenizers-0.21.0 transformers-4.48.0\nCollecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.6.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport gdown\nimport faiss\nimport pandas as pd\nimport re\nimport numpy as np\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:16:45.931001Z","iopub.execute_input":"2025-01-19T14:16:45.931452Z","iopub.status.idle":"2025-01-19T14:17:05.093083Z","shell.execute_reply.started":"2025-01-19T14:16:45.931405Z","shell.execute_reply":"2025-01-19T14:17:05.092358Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model_bge = SentenceTransformer(\"BAAI/bge-m3\")\nmodel_e5 = SentenceTransformer(\"intfloat/multilingual-e5-large\")\nmodel_tuned = SentenceTransformer(\"Quintu/bge-m3-legal_retrieval\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:17:05.094135Z","iopub.execute_input":"2025-01-19T14:17:05.094608Z","iopub.status.idle":"2025-01-19T14:18:51.288010Z","shell.execute_reply.started":"2025-01-19T14:17:05.094582Z","shell.execute_reply":"2025-01-19T14:18:51.287051Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b66f91154e04e2da824c25febf9cfc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cee4396516ba40b3b2e9c361d7ea77cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112e9b513dab43138e9773d1a4ae8a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143c69141bcb4ba080f5f49aeb869757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ecb29f24e29469eab90c93a71ce43e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b31737b384e4c0ea54b639df5ecdb28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acc77192845047c98959119a6cd9e448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645850b58e2c4e09a4ba74a83e7e6dfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799a64f7d78846219f94a144147df36a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7055ff5e019c44c1a692833f1b5be58f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f37505ea2f4fe68319de92286d85e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ca8659eb36a4180b7ec39f182441ddb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85d2b98fc9d443348aa119a53ceb9798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/160k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15582ce551ad41dba59b07afc513c508"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ecd42a035e94b0eb4fae6cf372479fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40d4be4f4d64e568d69608ca1f4d72f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d79526aeae64fd0af537815dcb1ce3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de7975ac09f6423cac1dc3be3d6192fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2165b02beb6341fc81a88926fdacab85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"114d54d93d1a432ab908ed4b81384003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be33a1c3197a4ca0bdbdb541e6ebe31b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5eef6a6295649419d87c4fcf829b8eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/734 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6550663511ba41eaa5e181f93ec6e816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0cc48aed87441b5b9267eefaaf20036"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0833885af25a48c1bcba1cbe4420f44f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e05241161444cb9419a5949bcef641"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25159a3832e546abbc5417e3299aa457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e75c168c84418e8b974ea0ef1b7c82"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# load faiss index\nindex_bge = faiss.read_index('/kaggle/input/bin-pretrained/bge_m3.bin')\nindex_e5 = faiss.read_index('/kaggle/input/bin-pretrained/e5.bin')\nindex_tuned = faiss.read_index('/kaggle/input/bge-m3-23400/bge_m3_23400.bin')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:18:51.289276Z","iopub.execute_input":"2025-01-19T14:18:51.289892Z","iopub.status.idle":"2025-01-19T14:19:11.131108Z","shell.execute_reply.started":"2025-01-19T14:18:51.289847Z","shell.execute_reply":"2025-01-19T14:19:11.130358Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/val-data/val_data.csv') \nquestions = data['question'].tolist()\nqids = data['qid'].tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:19:11.132215Z","iopub.execute_input":"2025-01-19T14:19:11.132587Z","iopub.status.idle":"2025-01-19T14:19:12.235513Z","shell.execute_reply.started":"2025-01-19T14:19:11.132533Z","shell.execute_reply":"2025-01-19T14:19:12.234558Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def process_cid(s):\n    s = s.strip('[]') \n    elements = re.split(r'[\\,\\s]+', s) \n    return [int(element) for element in elements if element.strip().isdigit()]  \n\nresult = {}\n\nfor idx, row in data.iterrows():\n    qid = row['qid']\n    cid = process_cid(row['cid'])\n    result[qid] = cid\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:19:12.236605Z","iopub.execute_input":"2025-01-19T14:19:12.236946Z","iopub.status.idle":"2025-01-19T14:19:13.342557Z","shell.execute_reply.started":"2025-01-19T14:19:12.236913Z","shell.execute_reply":"2025-01-19T14:19:13.341866Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# encode question\nembeddings_bge = model_bge.encode(questions)\nembeddings_e5 = model_e5.encode(questions)\nembeddings_tuned = model_tuned.encode(questions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:19:13.344528Z","iopub.execute_input":"2025-01-19T14:19:13.344807Z","iopub.status.idle":"2025-01-19T14:22:44.137585Z","shell.execute_reply.started":"2025-01-19T14:19:13.344780Z","shell.execute_reply":"2025-01-19T14:22:44.136857Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/744 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b29ee27541492c93b18db9a06447f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/744 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd5fd5c22ad24ea49d0fe70f17322267"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/744 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df942dd4a3e4699a1b6663192d70175"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def search_faiss(index, query_embedding, k=1500):\n    query_embedding = np.array(query_embedding).astype('float32')\n    distances, indices = index.search(query_embedding, k)  \n    return distances, indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:22:44.138960Z","iopub.execute_input":"2025-01-19T14:22:44.139245Z","iopub.status.idle":"2025-01-19T14:22:44.143636Z","shell.execute_reply.started":"2025-01-19T14:22:44.139217Z","shell.execute_reply":"2025-01-19T14:22:44.142766Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"distances_bge, indices_bge = search_faiss(index_bge, embeddings_bge)\ndistances_e5, indices_e5 = search_faiss(index_e5, embeddings_e5)\ndistance_tuned, indeces_tuned = search_faiss(index_tuned, embeddings_tuned)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:22:44.144641Z","iopub.execute_input":"2025-01-19T14:22:44.144873Z","iopub.status.idle":"2025-01-19T14:26:05.526858Z","shell.execute_reply.started":"2025-01-19T14:22:44.144851Z","shell.execute_reply":"2025-01-19T14:26:05.525864Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"npy_data = np.load('/kaggle/input/bm25-search/val_search_bm25.npy', allow_pickle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:26:05.528049Z","iopub.execute_input":"2025-01-19T14:26:05.528326Z","iopub.status.idle":"2025-01-19T14:26:06.143806Z","shell.execute_reply.started":"2025-01-19T14:26:05.528298Z","shell.execute_reply":"2025-01-19T14:26:06.142882Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"weight_bge = 1\nweight_e5 = 0\n\nall_id_with_score = []\ntop_k = 100\n\nfor i in range(len(indices_bge)):\n    bge_top_ids = indices_bge[i][:top_k]\n    bge_top_scores = distances_bge[i][:top_k]\n    e5_top_ids = indices_e5[i][:top_k]\n    e5_top_scores = distances_e5[i][:top_k]\n    bge_tuned_top_ids = indeces_tuned[i][:top_k]\n    bge_tuned_top_scores = distance_tuned[i][:top_k]\n    \n    combined_scores = {}\n\n    for idx, score in zip(bge_tuned_top_ids, bge_tuned_top_scores):\n        if idx not in combined_scores:\n            combined_scores[idx] = 0\n        combined_scores[idx] += weight_bge * score\n\n    for idx, score in zip(e5_top_ids, e5_top_scores):\n        if idx not in combined_scores:\n            combined_scores[idx] = 0\n        combined_scores[idx] += weight_e5 * score\n\n    cid_score_data = npy_data[i]\n\n    for cid, npy_score in cid_score_data:\n        if cid in combined_scores:\n            combined_scores[cid] *= npy_score \n    sorted_combined = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n    top_100_ids = [item[0] for item in sorted_combined[:100]]\n    all_id_with_score.append(top_100_ids)\n\n\nwith open('result_bi_encoder.txt', 'w') as f:\n    for qid, ids in zip(qids, all_id_with_score):\n        ids_str = ' '.join(map(str, ids))\n        f.write(f\"{qid} {ids_str}\\n\")\nprint(\"complete\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:44:59.178883Z","iopub.execute_input":"2025-01-19T14:44:59.179690Z","iopub.status.idle":"2025-01-19T14:45:11.663296Z","shell.execute_reply.started":"2025-01-19T14:44:59.179658Z","shell.execute_reply":"2025-01-19T14:45:11.662332Z"}},"outputs":[{"name":"stdout","text":"complete\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import os\nimport zipfile\n\noutput_folder = \"bge-bm25+bm25\"\nzip_filename = f\"{output_folder}.zip\"\nos.makedirs(output_folder, exist_ok=True)\n\nnum_parts = 9\nlines_per_part = len(qids) // num_parts\n\nfor part in range(num_parts):\n    file_path = os.path.join(output_folder, f'output_part_{part + 1}.txt')\n    with open(file_path, 'w') as f:\n        start_index = part * lines_per_part\n        end_index = (part + 1) * lines_per_part if part != num_parts - 1 else len(qids)\n        for qid, ids in zip(qids[start_index:end_index], all_id_with_score[start_index:end_index]):\n            ids_str = ' '.join(map(str, ids))\n            f.write(f\"{qid} {ids_str}\\n\")\n\n# Nén thư mục thành một file ZIP\n\nwith zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(output_folder):\n        for file in files:\n            file_path = os.path.join(root, file)\n            zipf.write(file_path, os.path.relpath(file_path, output_folder))\n\nprint(f\"All files are saved in '{output_folder}' and zipped as '{zip_filename}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:45:11.664747Z","iopub.execute_input":"2025-01-19T14:45:11.665039Z","iopub.status.idle":"2025-01-19T14:45:13.831992Z","shell.execute_reply.started":"2025-01-19T14:45:11.665013Z","shell.execute_reply":"2025-01-19T14:45:13.831075Z"}},"outputs":[{"name":"stdout","text":"All files are saved in 'bge-bm25+bm25' and zipped as 'bge-bm25+bm25.zip'.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"with open('/kaggle/input/template/template_chunking_flat.json', 'r', encoding='utf-8') as f:\n    json_data = json.load(f)\nstt_to_infor_id = {item['stt']: item['infor_id'] for item in json_data}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:45:13.832939Z","iopub.execute_input":"2025-01-19T14:45:13.833182Z","iopub.status.idle":"2025-01-19T14:45:18.335625Z","shell.execute_reply.started":"2025-01-19T14:45:13.833158Z","shell.execute_reply":"2025-01-19T14:45:18.334933Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"\n\nwith open('/kaggle/working/result_bi_encoder.txt', 'r', encoding='utf-8') as f:\n    lines = f.readlines()\n\nwith open('result_bi_encoder_convert.txt', 'w', encoding='utf-8') as f:\n    for line in lines:\n        if not line.strip():\n            continue\n        parts = line.strip().split()\n        qid = parts[0]\n        updated_ids = [stt_to_infor_id.get(int(stt), stt) for stt in parts[1:]]  \n        ids_str = ' '.join(map(str, updated_ids))\n        f.write(f\"{qid} {ids_str}\\n\")\n\nprint(\"File đã được lưu với infor_id thay vì stt.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:45:18.337655Z","iopub.execute_input":"2025-01-19T14:45:18.338356Z","iopub.status.idle":"2025-01-19T14:45:19.405722Z","shell.execute_reply.started":"2025-01-19T14:45:18.338313Z","shell.execute_reply":"2025-01-19T14:45:19.404875Z"}},"outputs":[{"name":"stdout","text":"File đã được lưu với infor_id thay vì stt.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"import pandas as pd\n\n\ndef convert_to_list(s):\n    s = s.strip('[]') \n    elements = s.split() \n    return [int(element) for element in elements]\n\ndef read_csv(file_path):\n    df = pd.read_csv(file_path)\n    df['cid'] = df['cid'].apply(convert_to_list)\n    return df\n\ndef read_txt(file_path):\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n    return [list(map(int, line.split())) for line in lines]\n\ndef calculate_mrr(submit, answer):\n    mrr_scores = []\n    for result in submit:\n        qid = result[0]  \n        cids = result[1:11]  \n        answer_cids = answer.get(qid, [])\n        rank = None\n        for i, cid in enumerate(cids):\n            if cid in answer_cids:  \n                rank = i + 1  \n                break\n        if rank: mrr_scores.append(1 / rank)\n    return sum(mrr_scores) / len(mrr_scores) if mrr_scores else 0\n\nanswer_df = read_csv('/kaggle/input/val-data/val_data.csv') \nsubmit_data = read_txt('/kaggle/working/result_bi_encoder_convert.txt')  \n\nanswer_dict = {row['qid']: row['cid'] for _, row in answer_df.iterrows()}\n\nmrr_score = calculate_mrr(submit_data, answer_dict)\nprint(f\"MRR@10: {mrr_score}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T14:45:19.406684Z","iopub.execute_input":"2025-01-19T14:45:19.406961Z","iopub.status.idle":"2025-01-19T14:45:21.511100Z","shell.execute_reply.started":"2025-01-19T14:45:19.406934Z","shell.execute_reply":"2025-01-19T14:45:21.510200Z"}},"outputs":[{"name":"stdout","text":"MRR@10: 0.7421349192439479\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}